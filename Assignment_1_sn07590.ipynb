{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadali74/MLAlgorithms/blob/master/Assignment_1_sn07590.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjtzTCY3ET4G"
      },
      "source": [
        "# CS 335: Introduction to Large Language Models\n",
        "## Assignment 01\n",
        "### **Total Marks**: 100\n",
        "### **Deadline**: Sunday, 3rd March, 2024, 11:59 PM\n",
        "### **Name**: Syed Muhammad Ali Naqvi\n",
        "### **ID**: sn07590"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_PuJY_809rM"
      },
      "source": [
        "#Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEsATiuR1Dm1"
      },
      "source": [
        "1. Please rename your notebook as *Assignment_1_aa1234.ipynb* before the final submission. Notebooks which do not follow appropriate naming convention will not be graded.\n",
        "\n",
        "2. Please submit your own work. If you have any questions, please feel free to reach out to the course instructors or RA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccbn_f1tuO5"
      },
      "source": [
        "# Assignment Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzVkeRPuFeE"
      },
      "source": [
        "In this assignment, you are required to fine tune a LLM model of your that classifies which human value category a textual arguement belongs to. Your model will evaluated against 1-baseline, random-baseline results on the following dataset: test, Nahjalbalagha, Zhihu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaTUH4roAbNK"
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUce6g7dikYE",
        "outputId": "a8e13327-c623-4521-e24d-28abcce89a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/280.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n"
          ]
        }
      ],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "!pip install accelerate -U\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, AutoModelForSequenceClassification, TrainingArguments, EvalPrediction\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nLW7X5DvLY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQpDqfqAeLf"
      },
      "source": [
        "# Download Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQHbYBWixhL"
      },
      "source": [
        "##Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNnoIZpRi4tG",
        "outputId": "40ca3584-f647-40a8-f176-47abd72e6ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-02 03:07:21--  https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/evaluator/evaluator.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8708 (8.5K) [text/plain]\n",
            "Saving to: ‘evaluator.py’\n",
            "\n",
            "evaluator.py        100%[===================>]   8.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-02 03:07:22 (60.1 MB/s) - ‘evaluator.py’ saved [8708/8708]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/evaluator/evaluator.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1cuD7diLpQt"
      },
      "source": [
        "## 1-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qemjimf_F124",
        "outputId": "5a9d4b3e-94bf-4a81-dcac-2240cddf5660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-02 03:07:22--  https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/1-baseline/1-baseline.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3613 (3.5K) [text/plain]\n",
            "Saving to: ‘1-baseline.py’\n",
            "\n",
            "1-baseline.py       100%[===================>]   3.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-02 03:07:22 (37.5 MB/s) - ‘1-baseline.py’ saved [3613/3613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/1-baseline/1-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpz1rfDxLsSd"
      },
      "source": [
        "## Random-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1T_HfBIL6cM",
        "outputId": "1ac793fd-b06a-471a-d97e-2dcad7fca6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-02 03:07:22--  https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/random-baseline/random-baseline.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5442 (5.3K) [text/plain]\n",
            "Saving to: ‘random-baseline.py’\n",
            "\n",
            "random-baseline.py  100%[===================>]   5.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-02 03:07:23 (63.8 MB/s) - ‘random-baseline.py’ saved [5442/5442]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/random-baseline/random-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hP4MSUBLw6d"
      },
      "source": [
        "## Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbW6yi3-kzLV",
        "outputId": "c133590b-e62d-4d34-e2a2-96f6da928e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-02 03:07:23--  https://zenodo.org/api/records/10564870/files-archive\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.79.172, 188.184.103.159, 188.184.98.238, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.79.172|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘files-archive’\n",
            "\n",
            "files-archive           [              <=>   ]  54.70M  15.6MB/s    in 4.3s    \n",
            "\n",
            "2024-03-02 03:07:29 (12.6 MB/s) - ‘files-archive’ saved [57353430]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://zenodo.org/api/records/10564870/files-archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqWSKoZYg889",
        "outputId": "7b5691b9-98ed-46a6-8202-215508ea7af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/files-archive\n",
            " extracting: Dataset/value-categories.json  \n",
            " extracting: Dataset/arguments-validation-zhihu.tsv  \n",
            " extracting: Dataset/level1-labels-training.tsv  \n",
            " extracting: Dataset/arguments-test-nahjalbalagha.tsv  \n",
            " extracting: Dataset/arguments-test.tsv  \n",
            " extracting: Dataset/arguments-training.tsv  \n",
            " extracting: Dataset/arguments-validation.tsv  \n",
            " extracting: Dataset/labels-test-nahjalbalagha.tsv  \n",
            " extracting: Dataset/labels-test-nyt.tsv  \n",
            " extracting: Dataset/labels-test.tsv  \n",
            " extracting: Dataset/labels-training.tsv  \n",
            " extracting: Dataset/level1-labels-test-nahjalbalagha.tsv  \n",
            " extracting: Dataset/level1-labels-test.tsv  \n",
            " extracting: Dataset/level1-labels-test-nyt.tsv  \n",
            " extracting: Dataset/labels-validation.tsv  \n",
            " extracting: Dataset/labels-validation-zhihu.tsv  \n",
            " extracting: Dataset/meta-arguments-g.tsv  \n",
            " extracting: Dataset/meta-arguments-c.tsv  \n",
            " extracting: Dataset/meta-arguments-e.tsv  \n",
            " extracting: Dataset/meta-arguments-f.tsv  \n",
            " extracting: Dataset/level1-labels-validation.tsv  \n",
            " extracting: Dataset/level1-labels-validation-zhihu.tsv  \n",
            " extracting: Dataset/meta-arguments-a.tsv  \n",
            " extracting: Dataset/meta-arguments-d.tsv  \n",
            " extracting: Dataset/annotations-level1.tsv  \n",
            " extracting: Dataset/README.md       \n",
            " extracting: Dataset/comments-level1.tsv  \n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!unzip /content/files-archive -d Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "slE4sixQO3g3"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/Dataset/zhihu\n",
        "!mkdir /content/Dataset/nahjalbalagha\n",
        "!mkdir /content/Dataset/train\n",
        "!mkdir /content/Dataset/test\n",
        "!mkdir /content/Dataset/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6j3XShbOUcK",
        "outputId": "3f6c7a82-f325-4815-aa06-2bce7a59a38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/Dataset/*-nahjalbalagha.tsv': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv /content/Dataset/*-zhihu.tsv /content/Dataset/zhihu\n",
        "!mv /content/Dataset/*-nahjalbalagha.tsv /content/Dataset/nahjalbalagha\n",
        "!mv /content/Dataset/*-nahjalbalagha.tsv /content/Dataset/nahjalbalagha\n",
        "!mv /content/Dataset/*-training.tsv /content/Dataset/train\n",
        "!mv /content/Dataset/*-test.tsv /content/Dataset/test\n",
        "!mv /content/Dataset/*-validation.tsv /content/Dataset/validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqfQxpk1rr3c"
      },
      "source": [
        "# Background Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VOGICHSEnPe"
      },
      "source": [
        "## Human Value Detection 2023 <br/>\n",
        "## SemEval 2023 Task 4. ValueEval: Identification of Human Values behind Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoK8u0VosGhF"
      },
      "source": [
        "\n",
        "\n",
        "Given a textual argument and a human value category, classify whether or not the argument draws on that category. This task uses a set of 20 value categories compiled from the social science literature and described in our [ACL paper](https://webis.de/publications.html#kiesel_2022b). Arguments are given as premise text, conclusion text, and binary stance of the premise to the conclusion (\"in favor of\" or \"against\").\n",
        "\n",
        "The 20 value categories are shown here on Schwartz' value continuum below:\n",
        "\n",
        "[![JEPBxUu.md.png](https://iili.io/JEPBxUu.md.png)](https://freeimage.host/i/JEPBxUu)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmfwBXIEqLN"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV37SsQqET4P"
      },
      "source": [
        "\n",
        "Data is provided as tab-separated values files with one header line. The arguments-validation.tsv files contain one argument per line: its unique argument ID, the conclusion, the premise's stance towards the conclusion, and the premise itself. Example with tab-separated columns are shown below\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Conclusion</span>\t<span class=\"column\">Stance</span>\t<span class=\"column\">Premise</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">We should prohibit school prayer</span>\t<span class=\"column\">against</span>\t<span class=\"column\">it should be allowed if the student wants to pray as long as it is not interfering with his classes</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">We should abolish the three-strikes laws</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">three strike laws can cause young people to be put away for life without a chance to straight out their life</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">The use of public defenders should be mandatory</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">the use of public defenders should be mandatory because some people don't have money for a lawyer and this would help those that don't</span>\n",
        "</pre>\n",
        "\n",
        "The labels-validation.tsv  files also contain one argument per line: its unique argument ID and one column for each of the 20 value categories with a 1 meaning that the argument resorts to the value category and a 0 that not. Example with tab-separated columns are shown below:\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Self-direction: thought</span>\t<span class=\"column\">Self-direction: action</span>\t<span class=\"column\">Stimulation</span>\t<span class=\"column\">Hedonism</span>\t<span class=\"column\">Achievement</span>\t<span class=\"column\">Power: dominance</span>\t<span class=\"column\">Power: resources</span>\t<span class=\"column\">Face</span>\t<span class=\"column\">Security: personal</span>\t<span class=\"column\">Security: societal</span>\t<span class=\"column\">Tradition</span>\t<span class=\"column\">Conformity: rules</span>\t<span class=\"column\">Conformity: interpersonal</span>\t<span class=\"column\">Humility</span>\t<span class=\"column\">Benevolence: caring</span>\t<span class=\"column\">Benevolence: dependability</span>\t<span class=\"column\">Universalism: concern</span>\t<span class=\"column\">Universalism: nature</span>\t<span class=\"column\">Universalism: tolerance</span>\t<span class=\"column\">Universalism: objectivity</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCUwSn5ET4R"
      },
      "source": [
        "In addition, there are other datasets for evaluating the robustness of our model: validation-zhihu from the recommendation and hotlist section of the Chinese question-answering website Zhihu, test-nahjalbalagha from and based on the Nahj al-Balagha.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTbj-CWGET4S"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0aIoUoET4T"
      },
      "source": [
        "Runs are evaluated on the basis of F1-score, Precision, and Recall: averaged over all value categories and for each category individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPq0nLudMRr6"
      },
      "source": [
        "## Baseline Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o3bNgmUjmBm7"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!mkdir /content/baseline\n",
        "!mkdir /content/output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiNl_AFGMlKm"
      },
      "source": [
        "### 1-Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aAGZXIoxSk"
      },
      "source": [
        "#### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9M_yVXkCci",
        "outputId": "e563e38c-75fd-40b1-e894-31ad2a5fcf4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/test/arguments-test.tsv\n",
            "Labeling 1576 instances\n",
            "Detected values: {'Benevolence: dependability', 'Self-direction: action', 'Universalism: objectivity', 'Power: resources', 'Conformity: rules', 'Universalism: tolerance', 'Security: societal', 'Security: personal', 'Humility', 'Benevolence: caring', 'Conformity: interpersonal', 'Hedonism', 'Achievement', 'Power: dominance', 'Universalism: concern', 'Tradition', 'Stimulation', 'Face', 'Universalism: nature', 'Self-direction: thought'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/test/labels-test.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 1576\n",
            "Run labels:   1576\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.26293020308065357\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.15136421319796953\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"1.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/test --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/test/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZimLuvQro0Un"
      },
      "source": [
        "#### Zhihu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdj9s6UapKNI",
        "outputId": "63882679-3317-4501-e30d-c13939aa5b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/zhihu/arguments-validation-zhihu.tsv\n",
            "Labeling 100 instances\n",
            "Detected values: {'Hedonism', 'Self-direction: thought', 'Universalism: concern', 'Humility', 'Face', 'Conformity: interpersonal', 'Security: societal', 'Universalism: objectivity', 'Security: personal', 'Achievement', 'Power: resources', 'Tradition', 'Self-direction: action', 'Stimulation', 'Conformity: rules', 'Power: dominance', 'Universalism: tolerance', 'Universalism: nature', 'Benevolence: dependability', 'Benevolence: caring'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/zhihu/labels-validation-zhihu.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 100\n",
            "Run labels:   100\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.2292179045745204\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.12944444444444445\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"1.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/zhihu/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/zhihu/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM73FR4vo32i"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1fhW1vnpUe3",
        "outputId": "6b00455e-2197-4359-c2c1-17903f39b0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\n",
            "Labeling 279 instances\n",
            "Detected values: {'Humility', 'Hedonism', 'Security: societal', 'Universalism: objectivity', 'Conformity: interpersonal', 'Power: resources', 'Universalism: tolerance', 'Benevolence: caring', 'Power: dominance', 'Self-direction: action', 'Face', 'Security: personal', 'Universalism: nature', 'Tradition', 'Achievement', 'Self-direction: thought', 'Stimulation', 'Conformity: rules', 'Benevolence: dependability', 'Universalism: concern'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 279\n",
            "Run labels:   279\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.12845882944826426\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.0686379928315412\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"1.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/nahjalbalagha/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/nahjalbalagha/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCKuzb-RMp6u"
      },
      "source": [
        "### Random-Baseline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k07k6xKvpAPO"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-SbkcWxr0Sv",
        "outputId": "b2707ca5-de0d-405f-8039-7f97eef2d6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/test/arguments-test.tsv\n",
            "Labeling 1576 instances\n",
            "Detected values: {'Achievement', 'Security: personal', 'Face', 'Self-direction: action', 'Benevolence: caring', 'Stimulation', 'Conformity: rules', 'Universalism: concern', 'Universalism: objectivity', 'Tradition', 'Power: resources', 'Conformity: interpersonal', 'Power: dominance', 'Benevolence: dependability', 'Security: societal', 'Hedonism', 'Universalism: nature', 'Humility', 'Self-direction: thought', 'Universalism: tolerance'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/test/labels-test.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 1576\n",
            "Run labels:   1576\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.16608921808129248\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.15550348857211035\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.17822144775672288\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/random-baseline.py --inputDataset /content/Dataset/test --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/test/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDhh7of4pCAS"
      },
      "source": [
        "#### Zhihu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN6mZ5jOr2Zp",
        "outputId": "43829983-e19b-4b2c-a6ef-9bb16dcc0064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/zhihu/arguments-validation-zhihu.tsv\n",
            "Labeling 100 instances\n",
            "Detected values: {'Security: societal', 'Self-direction: action', 'Face', 'Stimulation', 'Security: personal', 'Benevolence: caring', 'Power: dominance', 'Power: resources', 'Conformity: interpersonal', 'Humility', 'Tradition', 'Self-direction: thought', 'Universalism: objectivity', 'Benevolence: dependability', 'Achievement', 'Conformity: rules', 'Universalism: concern', 'Hedonism', 'Universalism: tolerance', 'Universalism: nature'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/zhihu/labels-validation-zhihu.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 100\n",
            "Run labels:   100\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.15573918118176303\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.12974292185194047\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.19476343548924194\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/random-baseline.py --inputDataset /content/Dataset/zhihu/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/zhihu/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gg-ZIzQpEn3"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WurMCZZSsBIU",
        "outputId": "1cc4fbad-c8dd-4441-d5b4-eaf3f64d59bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\n",
            "Labeling 279 instances\n",
            "Detected values: {'Power: dominance', 'Face', 'Universalism: concern', 'Security: societal', 'Benevolence: caring', 'Security: personal', 'Achievement', 'Universalism: objectivity', 'Benevolence: dependability', 'Self-direction: thought', 'Stimulation', 'Self-direction: action', 'Humility', 'Universalism: nature', 'Conformity: rules', 'Power: resources', 'Universalism: tolerance', 'Tradition', 'Conformity: interpersonal', 'Hedonism'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 279\n",
            "Run labels:   279\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.09227654825672356\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.06551438837109638\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.1560024250554273\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/random-baseline.py --inputDataset /content/Dataset/nahjalbalagha/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/nahjalbalagha/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aub8gmh_xfOz"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvwbxxhcwIwo"
      },
      "source": [
        "## [20 Points] Task 01 - Load Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ6f0D1zwj9P"
      },
      "source": [
        "In this task, you are required to load the Training, Test, Validation, Nahjalbalagha & Zhihu into seperate dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hicJHRw0piGN",
        "outputId": "fd280e00-2393-4c24-884f-a1c11ceeee92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5393, 4)\n",
            "(5393, 21)\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "# Training Data\n",
        "paths = {\"training\":\"training\", \"test\":\"test\", \"validation\":\"validation\", \"zhihu\":\"validation-zhihu\", \"nahjalbalagha\":\"test-nahjalbalagha\"}\n",
        "datasets = {\"training\":{}, \"test\":{}, \"validation\":{}, \"nahjalbalagha\":{}, \"zhihu\":{}}\n",
        "subset = [\"arguments\", \"labels\", \"level1-labels\"]\n",
        "\n",
        "\n",
        "for i in datasets.keys():\n",
        "  for j in subset:\n",
        "    if i == \"training\":\n",
        "      datasets[i][j] = (pd.read_csv(f\"/content/Dataset/train/{j}-{i}.tsv\", sep = \"\\t\"))\n",
        "    else:\n",
        "      datasets[i][j] = (pd.read_csv(f\"/content/Dataset/{i}/{j}-{paths[i]}.tsv\", sep = \"\\t\"))\n",
        "\n",
        "print(datasets['training']['arguments'].shape)\n",
        "print(datasets['training']['labels'].shape)\n",
        "\n",
        "# datasets['training']['labels'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpBfeP35A13l"
      },
      "source": [
        "## [10 Points] Task 02 - Define Tokenizer & Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-GrMJPcx3W3"
      },
      "source": [
        "In this task, you are required to define the Tokenizer and LLM model of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNVCZzye2Mz4"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "# picking the best model from the leaderboard :)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model = \"microsoft/phi-1_5\"\n",
        "model = \"bert-large-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case = True)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "rem_cols = [col for col in datasets['training']['labels'].columns[1:]]\n",
        "id2label = {idx:label for idx, label in enumerate(rem_cols)}\n",
        "label2id = {label:idx for idx, label in enumerate(rem_cols)}\n",
        "\n",
        "LLM = AutoModelForSequenceClassification.from_pretrained(model, num_labels=20, problem_type=\"multi_label_classification\", id2label=id2label, label2id=label2id)\n",
        "print(LLM)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHVo6_LBBmS"
      },
      "source": [
        "## [20 Points] Task 03 - Optimizer & Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_U-toJPyWU2"
      },
      "source": [
        "In this task, you are required to define the hyperparameters & the optimizer for training your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "IRCnPVc1y8C-"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "epochs = 4\n",
        "# MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = len(train_df) * epochs)\n",
        "training_args = TrainingArguments(\".\", evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
        "    num_train_epochs=epochs,\n",
        ")\n",
        "# training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0hSUmrBBGI4"
      },
      "source": [
        "## [20 Points] Task 04 -  Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIT5b7E6yuC3"
      },
      "source": [
        "In this task, you are required to implement the training loop for fine tuning your model. You are also required to plot on the same graph: Loss vs Epochs & Accuracy vs Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "K2wkC6syzMwB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f018d6b2-cd6f-4518-cc9d-9a9af3b83a12"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-230e9f8658de>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0meval_args2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arguments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Conclusion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_args2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0meval_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_args2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2913\u001b[0m                 )\n\u001b[1;32m   2914\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2915\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   2916\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m         \u001b[0;31m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3097\u001b[0;31m         padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n\u001b[0m\u001b[1;32m   3098\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m         \u001b[0;31m# Test if we have a padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDO_NOT_PAD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2735\u001b[0m                 \u001b[0;34m\"Asking to pad but the tokenizer does not have a padding token. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m                 \u001b[0;34m\"Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
          ]
        }
      ],
      "source": [
        "# Tokeninzing inputs\n",
        "import numpy as np\n",
        "\n",
        "# print(rem_cols)\n",
        "train_labels = datasets['training']['labels'][rem_cols]\n",
        "train_labels = np.array(train_labels.values.tolist())\n",
        "train_labels = train_labels.astype(np.float32)\n",
        "train_args = datasets['training']['arguments']['Premise'].values.tolist()\n",
        "train_args2 = datasets['training']['arguments']['Conclusion'].values.tolist()\n",
        "# print(train_args)\n",
        "# print(train_labels)\n",
        "eval_labels = datasets['validation']['labels'][rem_cols]\n",
        "eval_labels = np.array(eval_labels.values.tolist())\n",
        "eval_labels = eval_labels.astype(np.float32).tolist()\n",
        "eval_args = datasets['validation']['arguments']['Premise'].values.tolist()\n",
        "eval_args2 = datasets['validation']['arguments']['Conclusion'].values.tolist()\n",
        "\n",
        "train_encodings = tokenizer(train_args,train_args2, padding=True, truncation=True, max_length=512)\n",
        "eval_encodings = tokenizer(eval_args, eval_args2, padding=True, truncation=True, max_length=512)\n",
        "print(train_encodings[0].tokens)\n",
        "\n",
        "\n",
        "class TextClassifierDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = TextClassifierDataset(train_encodings, train_labels)\n",
        "eval_dataset = TextClassifierDataset(eval_encodings, eval_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Egtj2TzwzVrp",
        "outputId": "aa4267dd-9be6-4f8b-cbe8-925b9bc3d805"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1352' max='1352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1352/1352 12:42, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.354410</td>\n",
              "      <td>0.389772</td>\n",
              "      <td>0.623847</td>\n",
              "      <td>0.058544</td>\n",
              "      <td>0.665023</td>\n",
              "      <td>0.275672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.367100</td>\n",
              "      <td>0.332308</td>\n",
              "      <td>0.480833</td>\n",
              "      <td>0.667408</td>\n",
              "      <td>0.081751</td>\n",
              "      <td>0.697459</td>\n",
              "      <td>0.366882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.284800</td>\n",
              "      <td>0.328993</td>\n",
              "      <td>0.513069</td>\n",
              "      <td>0.687438</td>\n",
              "      <td>0.088608</td>\n",
              "      <td>0.667338</td>\n",
              "      <td>0.416732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.284800</td>\n",
              "      <td>0.331414</td>\n",
              "      <td>0.514809</td>\n",
              "      <td>0.688584</td>\n",
              "      <td>0.082806</td>\n",
              "      <td>0.666001</td>\n",
              "      <td>0.419563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1352, training_loss=0.3033712657951039, metrics={'train_runtime': 764.8564, 'train_samples_per_second': 28.204, 'train_steps_per_second': 1.768, 'total_flos': 1873770660823776.0, 'train_loss': 0.3033712657951039, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Write your code here\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def multi_label_metrics(predictions, labels, threshold=0.2):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average = 'micro');\n",
        "    recall = recall_score(y_true, y_pred, average = 'micro');\n",
        "    # return as dictionary\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy, 'precision': precision, 'recall': recall}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result\n",
        "\n",
        "\n",
        "trainer = Trainer(model=LLM,args=training_args,train_dataset=train_dataset,eval_dataset=eval_dataset, compute_metrics=compute_metrics)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NOEm2ezYUt"
      },
      "source": [
        "## [10 Points]  Task 05 - Model Evaluation: Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kjnR9qzuZG"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Test dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation function\n",
        "\n",
        "def model_evaluator(dataset, output_dir, threshold = 0.2):\n",
        "  prediction = []\n",
        "  test_args = datasets[dataset]['arguments']['Premise'].values.tolist()\n",
        "  test_args2 = datasets[dataset]['arguments']['Conclusion'].values.tolist()\n",
        "  for idx, text in enumerate(test_args):\n",
        "      text2 = test_args2[idx]\n",
        "      inputs = tokenizer(text,text2, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = LLM(**inputs)\n",
        "\n",
        "      logits = outputs.logits\n",
        "      probabilities = torch.sigmoid(logits)  # Apply sigmoid to convert logits to probabilities\n",
        "\n",
        "      predictions.append(probabilities)\n",
        "\n",
        "\n",
        "  predictions = np.array([tensor.cpu().numpy() for tensor in predictions])\n",
        "  # Define the new threshold (e.g., 0.4)\n",
        "  new_threshold = threshold\n",
        "\n",
        "  label_cols = rem_cols\n",
        "  # Create an empty DataFrame with the correct columns\n",
        "  df_submission = pd.DataFrame(columns = label_cols)\n",
        "\n",
        "  # Iterate through the rows of all_probabilities_array\n",
        "  for row in predictions:\n",
        "      # Create a mask for values greater than or equal to the new threshold\n",
        "      mask = row >= new_threshold\n",
        "\n",
        "      # Check if any value is above the threshold\n",
        "      if mask.any():\n",
        "          # If there is at least one value above the threshold, use the mask\n",
        "          thresholded_row = mask.astype(int)\n",
        "      else:\n",
        "          # If there are no values above the threshold, take the top 1 value\n",
        "          top_1_index = np.argmax(row)\n",
        "          thresholded_row = np.zeros(len(label_cols), dtype=int)\n",
        "          thresholded_row[top_1_index] = 1\n",
        "\n",
        "      # Reshape the thresholded_row to match the length of the index\n",
        "      thresholded_row = thresholded_row.reshape(1, -1)\n",
        "\n",
        "      # Append the thresholded row to the DataFrame\n",
        "      df_submission = df_submission.append(pd.DataFrame(thresholded_row, columns=label_cols), ignore_index=True)\n",
        "\n",
        "  # Convert the DataFrame to integer type\n",
        "  df_submission = df_submission.astype(int)\n",
        "\n",
        "  ids = datasets[dataset]['labels']['Argument ID']\n",
        "  run = pd.concat([ids, pred_df], axis = 1)\n",
        "  run.to_csv(f'{output_dir}/run.tsv, sep='\\t', index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "CbyfshWqcBkc",
        "outputId": "de0fd573-1cfe-4856-cf20-24615e5c7e74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (<ipython-input-1-9074bcfbe150>, line 55)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9074bcfbe150>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    run.to_csv(f'{output_dir}/run.tsv, sep='\\t', index=False)\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AkJAygxszgj7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "14ef5815-1a3d-43e9-dc9b-d9614c24da79"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c55bdb3839cd>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0;31m# See full discussion on the problems with returning `Union` here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0;31m# https://github.com/microsoft/pyright/issues/4213\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Write your code\n",
        "!mkdir '/content/trained_test'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LLM.to(device)\n",
        "# switchig model to evaluation mode\n",
        "\n",
        "\n",
        "LLM.eval()\n",
        "dataset = 'test'\n",
        "output_dir = '/content/trained_test'\n",
        "model_evaluator(dataset, output_dir)\n",
        "\n",
        "# predictions = []\n",
        "# # Process each text\n",
        "# test_args = datasets['test']['arguments']['Premise'].values.tolist()\n",
        "# test_args2 = datasets['test']['arguments']['Conclusion'].values.tolist()\n",
        "# for idx, text in enumerate(test_args):\n",
        "#     text2 = test_args2[idx]\n",
        "#     inputs = tokenizer(text,text2, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "#     inputs = inputs.to(device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         outputs = LLM(**inputs)\n",
        "\n",
        "#     logits = outputs.logits\n",
        "#     probabilities = torch.sigmoid(logits)  # Apply sigmoid to convert logits to probabilities\n",
        "\n",
        "#     predictions.append(probabilities)\n",
        "\n",
        "\n",
        "# predictions = np.array([tensor.cpu().numpy() for tensor in predictions])\n",
        "# # Define the new threshold (e.g., 0.4)\n",
        "# new_threshold = 0.5\n",
        "\n",
        "# label_cols = datasets['training']['labels'].columns[1:]\n",
        "# # Create an empty DataFrame with the correct columns\n",
        "# df_submission = pd.DataFrame(columns = label_cols)\n",
        "\n",
        "# # Iterate through the rows of all_probabilities_array\n",
        "# for row in predictions:\n",
        "#     # Create a mask for values greater than or equal to the new threshold\n",
        "#     mask = row >= new_threshold\n",
        "\n",
        "#     # Check if any value is above the threshold\n",
        "#     if mask.any():\n",
        "#         # If there is at least one value above the threshold, use the mask\n",
        "#         thresholded_row = mask.astype(int)\n",
        "#     else:\n",
        "#         # If there are no values above the threshold, take the top 1 value\n",
        "#         top_1_index = np.argmax(row)\n",
        "#         thresholded_row = np.zeros(len(label_cols), dtype=int)\n",
        "#         thresholded_row[top_1_index] = 1\n",
        "\n",
        "#     # Reshape the thresholded_row to match the length of the index\n",
        "#     thresholded_row = thresholded_row.reshape(1, -1)\n",
        "\n",
        "#     # Append the thresholded row to the DataFrame\n",
        "#     df_submission = df_submission.append(pd.DataFrame(thresholded_row, columns=label_cols), ignore_index=True)\n",
        "\n",
        "# # Convert the DataFrame to integer type\n",
        "# df_submission = df_submission.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_submission.head()\n",
        "\n",
        "# ids = datasets['test']['labels']['Argument ID']\n",
        "# run = pd.concat([ids, pred_df], axis = 1)\n",
        "# run.head()\n",
        "# run.to_csv('/content/trained/run.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXI1TJtDT6GY",
        "outputId": "02195ebc-535a-440d-b5ee-a595988395a3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/trained’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 evaluator.py --inputDataset /content/Dataset/test/ --inputRun /content/trained_test --outputDataset /content\n",
        "!head -n 12 /content/evaluation.prototext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbU6NiKFVl7s",
        "outputId": "6cf3b6ee-40e3-4263-d11e-149a6d47d2b3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/Dataset/test/labels-test.tsv\n",
            "Reading /content/trained/run.tsv\n",
            "Truth labels: 1576\n",
            "Run labels:   1576\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.39387456447527214\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.5546731244169848\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.3053532936131528\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU4HaMYnzhJv"
      },
      "source": [
        "## [10 Points]  Task 06 - Model Evaluation: Zhihu Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT5t6TbG0F_O"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Zhihu\n",
        " dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVP0kNHOzixT"
      },
      "outputs": [],
      "source": [
        "dataset = 'zhihu'\n",
        "output_dir = '/content/trained_zhihu'\n",
        "model_evaluator(dataset, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 evaluator.py --inputDataset /content/Dataset/zhihu/ --inputRun /content/trained_zhihu --outputDataset /content\n",
        "!head -n 12 /content/evaluation.prototext"
      ],
      "metadata": {
        "id": "lIy5ilZZeXRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4ZsjvNzj0-"
      },
      "source": [
        "## [10 Points]  Task 07 - Model Evaluation: Nahjalbalagha Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KkhxR3p0KAF"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Nahjalbalagha dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQnoTEUzlJU"
      },
      "outputs": [],
      "source": [
        "dataset = 'nahjalbalagha'\n",
        "output_dir = '/content/trained_nahjalbalagha'\n",
        "model_evaluator(dataset, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 evaluator.py --inputDataset /content/Dataset/nahjalbalagha/ --inputRun /content/trained_nahjalbalagha --outputDataset /content\n",
        "!head -n 12 /content/evaluation.prototext"
      ],
      "metadata": {
        "id": "J4qlTPZjet7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I0v4IKS0OA9"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6B-tga80RDu"
      },
      "source": [
        "In this section, cite any resources or references that you use for solving this assignment.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}